# Pytorch4Optimization
Some examples of optimization problem solved by using PyTorch Autograd

## Main idea
With all the interesting high-level architectures MLP is bringing (CNN, RNN, GNN...), it is easy to forget the core architecture of the learning algorithm which is to optimize a solution based on its gradients.

The goal of this repository is to show how we can resolve some simple optimization problems using the gradient descent algorithm implemented into PyTorch.

This is by going back to the basics that we can better understand and apply neural networks to new fields. For example, the core architecture of the CNN is to use back propagation to automate the creating of Kernels (https://en.wikipedia.org/wiki/Kernel_(image_processing)). The same process can be applied in robotics and many other computer tasks.
